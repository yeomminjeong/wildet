{"ast":null,"code":"import { convertToTensor } from '../../tensor_util_env';\nimport { cast } from '../cast';\nimport { div } from '../div';\nimport { Reduction } from '../loss_ops_utils';\nimport { mean } from '../mean';\nimport { mul } from '../mul';\nimport { notEqual } from '../not_equal';\nimport { ones } from '../ones';\nimport { op } from '../operation';\nimport { scalar } from '../scalar';\nimport { sum } from '../sum';\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ..., dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction computeWeightedLoss_(losses, weights) {\n  let reduction = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : Reduction.SUM_BY_NONZERO_WEIGHTS;\n  const $losses = convertToTensor(losses, 'losses', 'computeWeightedLoss');\n  let $weights = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'computeWeightedLoss');\n  }\n  const weightedLoss = $weights == null ? $losses : mul($losses, $weights);\n  if (reduction === Reduction.NONE) {\n    return weightedLoss;\n  }\n  if (reduction === Reduction.SUM) {\n    return sum(weightedLoss);\n  }\n  if (reduction === Reduction.MEAN) {\n    if ($weights == null) {\n      return mean(weightedLoss);\n    } else {\n      const broadcastFactor = $losses.size / $weights.size;\n      const result = div(sum(weightedLoss), sum($weights));\n      return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;\n    }\n  }\n  if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    if ($weights == null) {\n      return div(sum(weightedLoss), scalar($losses.size));\n    } else {\n      const broadcastedWeights = mul($weights, ones($losses.shape));\n      const numNonZeros = cast(sum(notEqual(broadcastedWeights, scalar(0))), 'float32');\n      return div(sum(weightedLoss), numNonZeros);\n    }\n  }\n  throw Error(`Unknown reduction: ${reduction}`);\n}\nexport const computeWeightedLoss = /* @__PURE__ */op({\n  computeWeightedLoss_\n});","map":{"version":3,"names":["convertToTensor","cast","div","Reduction","mean","mul","notEqual","ones","op","scalar","sum","computeWeightedLoss_","losses","weights","reduction","arguments","length","undefined","SUM_BY_NONZERO_WEIGHTS","$losses","$weights","weightedLoss","NONE","SUM","MEAN","broadcastFactor","size","result","broadcastedWeights","shape","numNonZeros","Error","computeWeightedLoss"],"sources":["/Users/minjeongyeom/Projects/project-wildet/tfjs-core/src/ops/losses/compute_weighted_loss.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\n\nimport {cast} from '../cast';\nimport {div} from '../div';\nimport {Reduction} from '../loss_ops_utils';\nimport {mean} from '../mean';\nimport {mul} from '../mul';\nimport {notEqual} from '../not_equal';\nimport {ones} from '../ones';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sum} from '../sum';\n\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ..., dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction computeWeightedLoss_<T extends Tensor, O extends Tensor>(\n    losses: T|TensorLike, weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $losses = convertToTensor(losses, 'losses', 'computeWeightedLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'computeWeightedLoss');\n  }\n\n  const weightedLoss = ($weights == null) ? $losses : mul($losses, $weights);\n\n  if (reduction === Reduction.NONE) {\n    return weightedLoss as O;\n  }\n  if (reduction === Reduction.SUM) {\n    return sum(weightedLoss);\n  }\n  if (reduction === Reduction.MEAN) {\n    if ($weights == null) {\n      return mean(weightedLoss);\n    } else {\n      const broadcastFactor = $losses.size / $weights.size;\n      const result = div(sum(weightedLoss), sum($weights));\n      return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) :\n                                   result as O;\n    }\n  }\n  if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    if ($weights == null) {\n      return div(sum(weightedLoss), scalar($losses.size));\n    } else {\n      const broadcastedWeights = mul($weights, ones($losses.shape));\n\n      const numNonZeros =\n          cast(sum(notEqual(broadcastedWeights, scalar(0))), 'float32');\n      return div(sum(weightedLoss), numNonZeros);\n    }\n  }\n\n  throw Error(`Unknown reduction: ${reduction}`);\n}\nexport const computeWeightedLoss = /* @__PURE__ */ op({computeWeightedLoss_});\n"],"mappings":"AAiBA,SAAQA,eAAe,QAAO,uBAAuB;AAGrD,SAAQC,IAAI,QAAO,SAAS;AAC5B,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,SAAS,QAAO,mBAAmB;AAC3C,SAAQC,IAAI,QAAO,SAAS;AAC5B,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,QAAQ,QAAO,cAAc;AACrC,SAAQC,IAAI,QAAO,SAAS;AAC5B,SAAQC,EAAE,QAAO,cAAc;AAC/B,SAAQC,MAAM,QAAO,WAAW;AAChC,SAAQC,GAAG,QAAO,QAAQ;AAE1B;;;;;;;;;;;AAWA,SAASC,oBAAoBA,CACzBC,MAAoB,EAAEC,OAA2B,EACL;EAAA,IAA5CC,SAAS,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAGZ,SAAS,CAACe,sBAAsB;EAC9C,MAAMC,OAAO,GAAGnB,eAAe,CAACY,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC;EACxE,IAAIQ,QAAQ,GAAW,IAAI;EAC3B,IAAIP,OAAO,IAAI,IAAI,EAAE;IACnBO,QAAQ,GAAGpB,eAAe,CAACa,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC;;EAGvE,MAAMQ,YAAY,GAAID,QAAQ,IAAI,IAAI,GAAID,OAAO,GAAGd,GAAG,CAACc,OAAO,EAAEC,QAAQ,CAAC;EAE1E,IAAIN,SAAS,KAAKX,SAAS,CAACmB,IAAI,EAAE;IAChC,OAAOD,YAAiB;;EAE1B,IAAIP,SAAS,KAAKX,SAAS,CAACoB,GAAG,EAAE;IAC/B,OAAOb,GAAG,CAACW,YAAY,CAAC;;EAE1B,IAAIP,SAAS,KAAKX,SAAS,CAACqB,IAAI,EAAE;IAChC,IAAIJ,QAAQ,IAAI,IAAI,EAAE;MACpB,OAAOhB,IAAI,CAACiB,YAAY,CAAC;KAC1B,MAAM;MACL,MAAMI,eAAe,GAAGN,OAAO,CAACO,IAAI,GAAGN,QAAQ,CAACM,IAAI;MACpD,MAAMC,MAAM,GAAGzB,GAAG,CAACQ,GAAG,CAACW,YAAY,CAAC,EAAEX,GAAG,CAACU,QAAQ,CAAC,CAAC;MACpD,OAAOK,eAAe,GAAG,CAAC,GAAGvB,GAAG,CAACyB,MAAM,EAAElB,MAAM,CAACgB,eAAe,CAAC,CAAC,GACpCE,MAAW;;;EAG5C,IAAIb,SAAS,KAAKX,SAAS,CAACe,sBAAsB,EAAE;IAClD,IAAIE,QAAQ,IAAI,IAAI,EAAE;MACpB,OAAOlB,GAAG,CAACQ,GAAG,CAACW,YAAY,CAAC,EAAEZ,MAAM,CAACU,OAAO,CAACO,IAAI,CAAC,CAAC;KACpD,MAAM;MACL,MAAME,kBAAkB,GAAGvB,GAAG,CAACe,QAAQ,EAAEb,IAAI,CAACY,OAAO,CAACU,KAAK,CAAC,CAAC;MAE7D,MAAMC,WAAW,GACb7B,IAAI,CAACS,GAAG,CAACJ,QAAQ,CAACsB,kBAAkB,EAAEnB,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC;MACjE,OAAOP,GAAG,CAACQ,GAAG,CAACW,YAAY,CAAC,EAAES,WAAW,CAAC;;;EAI9C,MAAMC,KAAK,CAAC,sBAAsBjB,SAAS,EAAE,CAAC;AAChD;AACA,OAAO,MAAMkB,mBAAmB,GAAG,eAAgBxB,EAAE,CAAC;EAACG;AAAoB,CAAC,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}