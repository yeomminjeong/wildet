{"ast":null,"code":"var _jsxFileName = \"/Users/minjeongyeom/Projects/project-wildet/wildet/src/components/WebcamVideo.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport axios from \"axios\";\nimport Analysising from \"./Analysising\";\n\n// export default function WebcamVideo() {\n//   const webcamRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const [recording, setRecording] = useState(false);\n//   const [videoUrl, setVideoUrl] = useState(\"\");\n//   const [isLoading, setIsLoading] = useState(false);\n\n//   const handleStartRecording = () => {\n//     setRecording(true);\n//     mediaRecorderRef.current = new MediaRecorder(webcamRef.current.stream);\n//     mediaRecorderRef.current.addEventListener(\n//       \"dataavailable\",\n//       handleDataAvailable\n//     );\n//     mediaRecorderRef.current.start();\n//   };\n\n//   const handleDataAvailable = (event) => {\n//     if (event.data.size > 0) {\n//       const videoBlob = new Blob([event.data], { type: \"video/mp4\" });\n//       const formData = new FormData();\n//       formData.append(\"file\", videoBlob);\n//       setIsLoading(true);\n//       axios\n//         .post(\"http://localhost:5000/detect\", formData, {\n//           headers: {\n//             \"Content-Type\": \"multipart/form-data\",\n//           },\n//           withCredentials: true,\n//           responseType: \"blob\", // blob 유형으로 응답 받음\n//         })\n//         .then((response) => {\n//           console.log(\"성공\");\n\n//           const videoBlob = new Blob([response.data], {\n//             type: \"video/mp4\",\n//           });\n\n//           setIsLoading(false);\n\n//           const videoUrl1 = URL.createObjectURL(videoBlob); // URL 객체로 변환\n//           setVideoUrl(videoUrl1);\n\n//           // const a = document.createElement(\"a\");\n//           // a.href = videoUrl1;\n//           // const videoName = `video_${new Date().getTime()}.mp4`;\n//           // a.download = videoName;\n//           // a.click();\n//         });\n//     }\n//   };\n\n//   console.log(videoUrl);\n\n//   const handleStopRecording = () => {\n//     mediaRecorderRef.current.stop();\n//   };\n\n//   const videoConstraints = {\n//     width: 420,\n//     height: 420,\n//     facingMode: \"user\",\n//   };\n\n//   // const handleVideoLoaded = (event) => {\n//   //   event.target.play();\n//   // };\n\n//   return (\n//     <div className=\"Container\">\n//       {isLoading ? (\n//         <div\n//           style={{\n//             color: \"white\",\n//           }}\n//         >\n//           객체 인식 중\n//         </div>\n//       ) : (\n//         <>\n//           {videoUrl ? (\n//             <button\n//               onClick={() => {\n//                 const a = document.createElement(\"a\");\n//                 a.href = videoUrl;\n//                 const videoName = `video_${new Date().getTime()}.mp4`;\n//                 a.download = videoName;\n//                 a.click();\n//               }}\n//             >\n//               다운로드\n//             </button>\n//           ) : (\n//             <Webcam\n//               height={400}\n//               width={400}\n//               audio={false}\n//               mirrored={true}\n//               ref={webcamRef}\n//               videoConstraints={videoConstraints}\n//             />\n//           )}\n//           {recording ? (\n//             <button onClick={handleStopRecording}>Stop Recording</button>\n//           ) : (\n//             <button onClick={handleStartRecording}>Start Recording</button>\n//           )}\n//         </>\n//       )}\n//     </div>\n//   );\n// }\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function WebcamVideo() {\n  _s();\n  const videoRef = useRef(null);\n  useEffect(() => {\n    const loadModelAndDetect = async () => {\n      // TensorFlow.js 모델을 로드합니다.\n      const model = await tf.loadLayersModel(\"../detect/tfjs_model/model.json\");\n      const detectObjects = () => {\n        // 비디오 프레임을 캡처합니다.\n        const video = videoRef.current;\n        const image = tf.browser.fromPixels(video);\n        const expandedImage = image.expandDims(0);\n\n        // 객체 인식을 수행합니다.\n        const predictions = model.predict(expandedImage);\n\n        // 결과를 처리하고 화면에 실시간 객체 인식 결과를 표시하는 로직을 구현합니다.\n        // predictions를 활용하여 실시간으로 객체 인식 결과를 화면에 표시하는 코드를 작성하세요.\n        // 예시:\n        // const boxes = await predictions[0].array();\n        // const classes = await predictions[1].array();\n        // const scores = await predictions[2].array();\n        // console.log(boxes, classes, scores);\n\n        // 다음 프레임을 처리하기 위해 재귀적으로 호출합니다.\n        requestAnimationFrame(detectObjects);\n      };\n\n      // 객체 인식을 시작합니다.\n      detectObjects();\n    };\n\n    // 웹캠 스트림에 접근하고 객체 인식을 시작합니다.\n    navigator.mediaDevices.getUserMedia({\n      video: true\n    }).then(stream => {\n      videoRef.current.srcObject = stream;\n      videoRef.current.onloadedmetadata = () => {\n        loadModelAndDetect();\n      };\n    }).catch(error => {\n      console.log(\"웹캠 접근 오류:\", error);\n    });\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"Container\",\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      id: \"video\",\n      width: 400,\n      height: 400,\n      autoPlay: true,\n      ref: videoRef,\n      style: {\n        transform: \"scaleX(-1)\"\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 171,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 170,\n    columnNumber: 5\n  }, this);\n}\n_s(WebcamVideo, \"PdMsmLAy5JKU3vCrhAlqGYQfKuA=\");\n_c = WebcamVideo;\nvar _c;\n$RefreshReg$(_c, \"WebcamVideo\");","map":{"version":3,"names":["React","useState","useRef","useEffect","Webcam","axios","Analysising","tf","jsxDEV","_jsxDEV","WebcamVideo","_s","videoRef","loadModelAndDetect","model","loadLayersModel","detectObjects","video","current","image","browser","fromPixels","expandedImage","expandDims","predictions","predict","requestAnimationFrame","navigator","mediaDevices","getUserMedia","then","stream","srcObject","onloadedmetadata","catch","error","console","log","className","children","id","width","height","autoPlay","ref","style","transform","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/minjeongyeom/Projects/project-wildet/wildet/src/components/WebcamVideo.jsx"],"sourcesContent":["import React, { useState, useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport axios from \"axios\";\nimport Analysising from \"./Analysising\";\n\n// export default function WebcamVideo() {\n//   const webcamRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const [recording, setRecording] = useState(false);\n//   const [videoUrl, setVideoUrl] = useState(\"\");\n//   const [isLoading, setIsLoading] = useState(false);\n\n//   const handleStartRecording = () => {\n//     setRecording(true);\n//     mediaRecorderRef.current = new MediaRecorder(webcamRef.current.stream);\n//     mediaRecorderRef.current.addEventListener(\n//       \"dataavailable\",\n//       handleDataAvailable\n//     );\n//     mediaRecorderRef.current.start();\n//   };\n\n//   const handleDataAvailable = (event) => {\n//     if (event.data.size > 0) {\n//       const videoBlob = new Blob([event.data], { type: \"video/mp4\" });\n//       const formData = new FormData();\n//       formData.append(\"file\", videoBlob);\n//       setIsLoading(true);\n//       axios\n//         .post(\"http://localhost:5000/detect\", formData, {\n//           headers: {\n//             \"Content-Type\": \"multipart/form-data\",\n//           },\n//           withCredentials: true,\n//           responseType: \"blob\", // blob 유형으로 응답 받음\n//         })\n//         .then((response) => {\n//           console.log(\"성공\");\n\n//           const videoBlob = new Blob([response.data], {\n//             type: \"video/mp4\",\n//           });\n\n//           setIsLoading(false);\n\n//           const videoUrl1 = URL.createObjectURL(videoBlob); // URL 객체로 변환\n//           setVideoUrl(videoUrl1);\n\n//           // const a = document.createElement(\"a\");\n//           // a.href = videoUrl1;\n//           // const videoName = `video_${new Date().getTime()}.mp4`;\n//           // a.download = videoName;\n//           // a.click();\n//         });\n//     }\n//   };\n\n//   console.log(videoUrl);\n\n//   const handleStopRecording = () => {\n//     mediaRecorderRef.current.stop();\n//   };\n\n//   const videoConstraints = {\n//     width: 420,\n//     height: 420,\n//     facingMode: \"user\",\n//   };\n\n//   // const handleVideoLoaded = (event) => {\n//   //   event.target.play();\n//   // };\n\n//   return (\n//     <div className=\"Container\">\n//       {isLoading ? (\n//         <div\n//           style={{\n//             color: \"white\",\n//           }}\n//         >\n//           객체 인식 중\n//         </div>\n//       ) : (\n//         <>\n//           {videoUrl ? (\n//             <button\n//               onClick={() => {\n//                 const a = document.createElement(\"a\");\n//                 a.href = videoUrl;\n//                 const videoName = `video_${new Date().getTime()}.mp4`;\n//                 a.download = videoName;\n//                 a.click();\n//               }}\n//             >\n//               다운로드\n//             </button>\n//           ) : (\n//             <Webcam\n//               height={400}\n//               width={400}\n//               audio={false}\n//               mirrored={true}\n//               ref={webcamRef}\n//               videoConstraints={videoConstraints}\n//             />\n//           )}\n//           {recording ? (\n//             <button onClick={handleStopRecording}>Stop Recording</button>\n//           ) : (\n//             <button onClick={handleStartRecording}>Start Recording</button>\n//           )}\n//         </>\n//       )}\n//     </div>\n//   );\n// }\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs\";\n\nexport default function WebcamVideo() {\n  const videoRef = useRef(null);\n\n  useEffect(() => {\n    const loadModelAndDetect = async () => {\n      // TensorFlow.js 모델을 로드합니다.\n      const model = await tf.loadLayersModel(\"../detect/tfjs_model/model.json\");\n\n      const detectObjects = () => {\n        // 비디오 프레임을 캡처합니다.\n        const video = videoRef.current;\n        const image = tf.browser.fromPixels(video);\n        const expandedImage = image.expandDims(0);\n\n        // 객체 인식을 수행합니다.\n        const predictions = model.predict(expandedImage);\n\n        // 결과를 처리하고 화면에 실시간 객체 인식 결과를 표시하는 로직을 구현합니다.\n        // predictions를 활용하여 실시간으로 객체 인식 결과를 화면에 표시하는 코드를 작성하세요.\n        // 예시:\n        // const boxes = await predictions[0].array();\n        // const classes = await predictions[1].array();\n        // const scores = await predictions[2].array();\n        // console.log(boxes, classes, scores);\n\n        // 다음 프레임을 처리하기 위해 재귀적으로 호출합니다.\n        requestAnimationFrame(detectObjects);\n      };\n\n      // 객체 인식을 시작합니다.\n      detectObjects();\n    };\n\n    // 웹캠 스트림에 접근하고 객체 인식을 시작합니다.\n    navigator.mediaDevices\n      .getUserMedia({ video: true })\n      .then((stream) => {\n        videoRef.current.srcObject = stream;\n        videoRef.current.onloadedmetadata = () => {\n          loadModelAndDetect();\n        };\n      })\n      .catch((error) => {\n        console.log(\"웹캠 접근 오류:\", error);\n      });\n  }, []);\n\n  return (\n    <div className=\"Container\">\n      <video\n        id=\"video\"\n        width={400}\n        height={400}\n        autoPlay\n        ref={videoRef}\n        style={{ transform: \"scaleX(-1)\" }}\n      />\n    </div>\n  );\n}\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAC1D,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAOC,KAAK,MAAM,OAAO;AACzB,OAAOC,WAAW,MAAM,eAAe;;AAEvC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,kBAAkB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1B,eAAe,SAASC,WAAWA,CAAA,EAAG;EAAAC,EAAA;EACpC,MAAMC,QAAQ,GAAGV,MAAM,CAAC,IAAI,CAAC;EAE7BC,SAAS,CAAC,MAAM;IACd,MAAMU,kBAAkB,GAAG,MAAAA,CAAA,KAAY;MACrC;MACA,MAAMC,KAAK,GAAG,MAAMP,EAAE,CAACQ,eAAe,CAAC,iCAAiC,CAAC;MAEzE,MAAMC,aAAa,GAAGA,CAAA,KAAM;QAC1B;QACA,MAAMC,KAAK,GAAGL,QAAQ,CAACM,OAAO;QAC9B,MAAMC,KAAK,GAAGZ,EAAE,CAACa,OAAO,CAACC,UAAU,CAACJ,KAAK,CAAC;QAC1C,MAAMK,aAAa,GAAGH,KAAK,CAACI,UAAU,CAAC,CAAC,CAAC;;QAEzC;QACA,MAAMC,WAAW,GAAGV,KAAK,CAACW,OAAO,CAACH,aAAa,CAAC;;QAEhD;QACA;QACA;QACA;QACA;QACA;QACA;;QAEA;QACAI,qBAAqB,CAACV,aAAa,CAAC;MACtC,CAAC;;MAED;MACAA,aAAa,EAAE;IACjB,CAAC;;IAED;IACAW,SAAS,CAACC,YAAY,CACnBC,YAAY,CAAC;MAAEZ,KAAK,EAAE;IAAK,CAAC,CAAC,CAC7Ba,IAAI,CAAEC,MAAM,IAAK;MAChBnB,QAAQ,CAACM,OAAO,CAACc,SAAS,GAAGD,MAAM;MACnCnB,QAAQ,CAACM,OAAO,CAACe,gBAAgB,GAAG,MAAM;QACxCpB,kBAAkB,EAAE;MACtB,CAAC;IACH,CAAC,CAAC,CACDqB,KAAK,CAAEC,KAAK,IAAK;MAChBC,OAAO,CAACC,GAAG,CAAC,WAAW,EAAEF,KAAK,CAAC;IACjC,CAAC,CAAC;EACN,CAAC,EAAE,EAAE,CAAC;EAEN,oBACE1B,OAAA;IAAK6B,SAAS,EAAC,WAAW;IAAAC,QAAA,eACxB9B,OAAA;MACE+B,EAAE,EAAC,OAAO;MACVC,KAAK,EAAE,GAAI;MACXC,MAAM,EAAE,GAAI;MACZC,QAAQ;MACRC,GAAG,EAAEhC,QAAS;MACdiC,KAAK,EAAE;QAAEC,SAAS,EAAE;MAAa;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EACnC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,QACE;AAEV;AAACvC,EAAA,CA3DuBD,WAAW;AAAAyC,EAAA,GAAXzC,WAAW;AAAA,IAAAyC,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}