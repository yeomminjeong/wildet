{"ast":null,"code":"import React, { useState, useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport axios from \"axios\";\nimport Analysising from \"./Analysising\";\n\n// export default function WebcamVideo() {\n//   const webcamRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const [recording, setRecording] = useState(false);\n//   const [videoUrl, setVideoUrl] = useState(\"\");\n//   const [isLoading, setIsLoading] = useState(false);\n\n//   const handleStartRecording = () => {\n//     setRecording(true);\n//     mediaRecorderRef.current = new MediaRecorder(webcamRef.current.stream);\n//     mediaRecorderRef.current.addEventListener(\n//       \"dataavailable\",\n//       handleDataAvailable\n//     );\n//     mediaRecorderRef.current.start();\n//   };\n\n//   const handleDataAvailable = (event) => {\n//     if (event.data.size > 0) {\n//       const videoBlob = new Blob([event.data], { type: \"video/mp4\" });\n//       const formData = new FormData();\n//       formData.append(\"file\", videoBlob);\n//       setIsLoading(true);\n//       axios\n//         .post(\"http://localhost:5000/detect\", formData, {\n//           headers: {\n//             \"Content-Type\": \"multipart/form-data\",\n//           },\n//           withCredentials: true,\n//           responseType: \"blob\", // blob 유형으로 응답 받음\n//         })\n//         .then((response) => {\n//           console.log(\"성공\");\n\n//           const videoBlob = new Blob([response.data], {\n//             type: \"video/mp4\",\n//           });\n\n//           setIsLoading(false);\n\n//           const videoUrl1 = URL.createObjectURL(videoBlob); // URL 객체로 변환\n//           setVideoUrl(videoUrl1);\n\n//           // const a = document.createElement(\"a\");\n//           // a.href = videoUrl1;\n//           // const videoName = `video_${new Date().getTime()}.mp4`;\n//           // a.download = videoName;\n//           // a.click();\n//         });\n//     }\n//   };\n\n//   console.log(videoUrl);\n\n//   const handleStopRecording = () => {\n//     mediaRecorderRef.current.stop();\n//   };\n\n//   const videoConstraints = {\n//     width: 420,\n//     height: 420,\n//     facingMode: \"user\",\n//   };\n\n//   // const handleVideoLoaded = (event) => {\n//   //   event.target.play();\n//   // };\n\n//   return (\n//     <div className=\"Container\">\n//       {isLoading ? (\n//         <div\n//           style={{\n//             color: \"white\",\n//           }}\n//         >\n//           객체 인식 중\n//         </div>\n//       ) : (\n//         <>\n//           {videoUrl ? (\n//             <button\n//               onClick={() => {\n//                 const a = document.createElement(\"a\");\n//                 a.href = videoUrl;\n//                 const videoName = `video_${new Date().getTime()}.mp4`;\n//                 a.download = videoName;\n//                 a.click();\n//               }}\n//             >\n//               다운로드\n//             </button>\n//           ) : (\n//             <Webcam\n//               height={400}\n//               width={400}\n//               audio={false}\n//               mirrored={true}\n//               ref={webcamRef}\n//               videoConstraints={videoConstraints}\n//             />\n//           )}\n//           {recording ? (\n//             <button onClick={handleStopRecording}>Stop Recording</button>\n//           ) : (\n//             <button onClick={handleStartRecording}>Start Recording</button>\n//           )}\n//         </>\n//       )}\n//     </div>\n//   );\n// }\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs\";\nexport default function WebcamVideo() {\n  // 웹캠 비디오 요소를 가져옵니다.\n  const videoElement = document.getElementById(\"video\");\n\n  // 웹캠 비디오 스트림을 가져옵니다.\n  navigator.mediaDevices.getUserMedia({\n    video: true\n  }).then(stream => {\n    // 웹캠 비디오 요소에 스트림을 설정합니다.\n    videoElement.srcObject = stream;\n    videoElement.onloadedmetadata = () => {\n      // 웹캠 비디오 로드 완료 후 객체 인식 모델을 로드하고 실행합니다.\n      loadModelAndDetect();\n    };\n  });\n  async function loadModelAndDetect() {\n    // 사용자가 만든 TensorFlow.js 모델을 로드합니다.\n    const model = await tf.loadLayersModel(\"../detect/tfjs_model/model.json\");\n\n    // 비디오 요소에서 프레임을 캡처하고 객체 인식을 수행합니다.\n    function detectObjects() {\n      // 비디오 프레임 캡처\n      const image = tf.browser.fromPixels(videoElement);\n      const expandedImage = image.expandDims(0);\n\n      // 객체 인식 실행\n      const predictions = model.predict(expandedImage);\n\n      // 결과 처리\n      // 예측 결과를 활용하여 실시간으로 객체 인식 결과를 화면에 표시하는 로직을 구현합니다.\n\n      // 다음 프레임을 처리하기 위해 재귀적으로 호출\n      requestAnimationFrame(detectObjects);\n    }\n\n    // 객체 인식 실행\n    detectObjects();\n  }\n}\n_c = WebcamVideo;\nvar _c;\n$RefreshReg$(_c, \"WebcamVideo\");","map":{"version":3,"names":["React","useState","useRef","useEffect","Webcam","axios","Analysising","tf","WebcamVideo","videoElement","document","getElementById","navigator","mediaDevices","getUserMedia","video","then","stream","srcObject","onloadedmetadata","loadModelAndDetect","model","loadLayersModel","detectObjects","image","browser","fromPixels","expandedImage","expandDims","predictions","predict","requestAnimationFrame","_c","$RefreshReg$"],"sources":["/Users/minjeongyeom/Projects/project-wildet/wildet/src/components/WebcamVideo.jsx"],"sourcesContent":["import React, { useState, useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport axios from \"axios\";\nimport Analysising from \"./Analysising\";\n\n// export default function WebcamVideo() {\n//   const webcamRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const [recording, setRecording] = useState(false);\n//   const [videoUrl, setVideoUrl] = useState(\"\");\n//   const [isLoading, setIsLoading] = useState(false);\n\n//   const handleStartRecording = () => {\n//     setRecording(true);\n//     mediaRecorderRef.current = new MediaRecorder(webcamRef.current.stream);\n//     mediaRecorderRef.current.addEventListener(\n//       \"dataavailable\",\n//       handleDataAvailable\n//     );\n//     mediaRecorderRef.current.start();\n//   };\n\n//   const handleDataAvailable = (event) => {\n//     if (event.data.size > 0) {\n//       const videoBlob = new Blob([event.data], { type: \"video/mp4\" });\n//       const formData = new FormData();\n//       formData.append(\"file\", videoBlob);\n//       setIsLoading(true);\n//       axios\n//         .post(\"http://localhost:5000/detect\", formData, {\n//           headers: {\n//             \"Content-Type\": \"multipart/form-data\",\n//           },\n//           withCredentials: true,\n//           responseType: \"blob\", // blob 유형으로 응답 받음\n//         })\n//         .then((response) => {\n//           console.log(\"성공\");\n\n//           const videoBlob = new Blob([response.data], {\n//             type: \"video/mp4\",\n//           });\n\n//           setIsLoading(false);\n\n//           const videoUrl1 = URL.createObjectURL(videoBlob); // URL 객체로 변환\n//           setVideoUrl(videoUrl1);\n\n//           // const a = document.createElement(\"a\");\n//           // a.href = videoUrl1;\n//           // const videoName = `video_${new Date().getTime()}.mp4`;\n//           // a.download = videoName;\n//           // a.click();\n//         });\n//     }\n//   };\n\n//   console.log(videoUrl);\n\n//   const handleStopRecording = () => {\n//     mediaRecorderRef.current.stop();\n//   };\n\n//   const videoConstraints = {\n//     width: 420,\n//     height: 420,\n//     facingMode: \"user\",\n//   };\n\n//   // const handleVideoLoaded = (event) => {\n//   //   event.target.play();\n//   // };\n\n//   return (\n//     <div className=\"Container\">\n//       {isLoading ? (\n//         <div\n//           style={{\n//             color: \"white\",\n//           }}\n//         >\n//           객체 인식 중\n//         </div>\n//       ) : (\n//         <>\n//           {videoUrl ? (\n//             <button\n//               onClick={() => {\n//                 const a = document.createElement(\"a\");\n//                 a.href = videoUrl;\n//                 const videoName = `video_${new Date().getTime()}.mp4`;\n//                 a.download = videoName;\n//                 a.click();\n//               }}\n//             >\n//               다운로드\n//             </button>\n//           ) : (\n//             <Webcam\n//               height={400}\n//               width={400}\n//               audio={false}\n//               mirrored={true}\n//               ref={webcamRef}\n//               videoConstraints={videoConstraints}\n//             />\n//           )}\n//           {recording ? (\n//             <button onClick={handleStopRecording}>Stop Recording</button>\n//           ) : (\n//             <button onClick={handleStartRecording}>Start Recording</button>\n//           )}\n//         </>\n//       )}\n//     </div>\n//   );\n// }\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs\";\n\nexport default function WebcamVideo() {\n  // 웹캠 비디오 요소를 가져옵니다.\n  const videoElement = document.getElementById(\"video\");\n\n  // 웹캠 비디오 스트림을 가져옵니다.\n  navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {\n    // 웹캠 비디오 요소에 스트림을 설정합니다.\n    videoElement.srcObject = stream;\n    videoElement.onloadedmetadata = () => {\n      // 웹캠 비디오 로드 완료 후 객체 인식 모델을 로드하고 실행합니다.\n      loadModelAndDetect();\n    };\n  });\n\n  async function loadModelAndDetect() {\n    // 사용자가 만든 TensorFlow.js 모델을 로드합니다.\n    const model = await tf.loadLayersModel(\"../detect/tfjs_model/model.json\");\n\n    // 비디오 요소에서 프레임을 캡처하고 객체 인식을 수행합니다.\n    function detectObjects() {\n      // 비디오 프레임 캡처\n      const image = tf.browser.fromPixels(videoElement);\n      const expandedImage = image.expandDims(0);\n\n      // 객체 인식 실행\n      const predictions = model.predict(expandedImage);\n\n      // 결과 처리\n      // 예측 결과를 활용하여 실시간으로 객체 인식 결과를 화면에 표시하는 로직을 구현합니다.\n\n      // 다음 프레임을 처리하기 위해 재귀적으로 호출\n      requestAnimationFrame(detectObjects);\n    }\n\n    // 객체 인식 실행\n    detectObjects();\n  }\n}\n"],"mappings":"AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAC1D,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAOC,KAAK,MAAM,OAAO;AACzB,OAAOC,WAAW,MAAM,eAAe;;AAEvC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,kBAAkB;AAEzB,eAAe,SAASC,WAAWA,CAAA,EAAG;EACpC;EACA,MAAMC,YAAY,GAAGC,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC;;EAErD;EACAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;IAAEC,KAAK,EAAE;EAAK,CAAC,CAAC,CAACC,IAAI,CAAEC,MAAM,IAAK;IACpE;IACAR,YAAY,CAACS,SAAS,GAAGD,MAAM;IAC/BR,YAAY,CAACU,gBAAgB,GAAG,MAAM;MACpC;MACAC,kBAAkB,EAAE;IACtB,CAAC;EACH,CAAC,CAAC;EAEF,eAAeA,kBAAkBA,CAAA,EAAG;IAClC;IACA,MAAMC,KAAK,GAAG,MAAMd,EAAE,CAACe,eAAe,CAAC,iCAAiC,CAAC;;IAEzE;IACA,SAASC,aAAaA,CAAA,EAAG;MACvB;MACA,MAAMC,KAAK,GAAGjB,EAAE,CAACkB,OAAO,CAACC,UAAU,CAACjB,YAAY,CAAC;MACjD,MAAMkB,aAAa,GAAGH,KAAK,CAACI,UAAU,CAAC,CAAC,CAAC;;MAEzC;MACA,MAAMC,WAAW,GAAGR,KAAK,CAACS,OAAO,CAACH,aAAa,CAAC;;MAEhD;MACA;;MAEA;MACAI,qBAAqB,CAACR,aAAa,CAAC;IACtC;;IAEA;IACAA,aAAa,EAAE;EACjB;AACF;AAACS,EAAA,GArCuBxB,WAAW;AAAA,IAAAwB,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}