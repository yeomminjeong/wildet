{"ast":null,"code":"import React, { useState, useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport axios from \"axios\";\nimport Analysising from \"./Analysising\";\n\n// export default function WebcamVideo() {\n//   const webcamRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const [recording, setRecording] = useState(false);\n//   const [videoUrl, setVideoUrl] = useState(\"\");\n//   const [isLoading, setIsLoading] = useState(false);\n\n//   const handleStartRecording = () => {\n//     setRecording(true);\n//     mediaRecorderRef.current = new MediaRecorder(webcamRef.current.stream);\n//     mediaRecorderRef.current.addEventListener(\n//       \"dataavailable\",\n//       handleDataAvailable\n//     );\n//     mediaRecorderRef.current.start();\n//   };\n\n//   const handleDataAvailable = (event) => {\n//     if (event.data.size > 0) {\n//       const videoBlob = new Blob([event.data], { type: \"video/mp4\" });\n//       const formData = new FormData();\n//       formData.append(\"file\", videoBlob);\n//       setIsLoading(true);\n//       axios\n//         .post(\"http://localhost:5000/detect\", formData, {\n//           headers: {\n//             \"Content-Type\": \"multipart/form-data\",\n//           },\n//           withCredentials: true,\n//           responseType: \"blob\", // blob 유형으로 응답 받음\n//         })\n//         .then((response) => {\n//           console.log(\"성공\");\n\n//           const videoBlob = new Blob([response.data], {\n//             type: \"video/mp4\",\n//           });\n\n//           setIsLoading(false);\n\n//           const videoUrl1 = URL.createObjectURL(videoBlob); // URL 객체로 변환\n//           setVideoUrl(videoUrl1);\n\n//           // const a = document.createElement(\"a\");\n//           // a.href = videoUrl1;\n//           // const videoName = `video_${new Date().getTime()}.mp4`;\n//           // a.download = videoName;\n//           // a.click();\n//         });\n//     }\n//   };\n\n//   console.log(videoUrl);\n\n//   const handleStopRecording = () => {\n//     mediaRecorderRef.current.stop();\n//   };\n\n//   const videoConstraints = {\n//     width: 420,\n//     height: 420,\n//     facingMode: \"user\",\n//   };\n\n//   // const handleVideoLoaded = (event) => {\n//   //   event.target.play();\n//   // };\n\n//   return (\n//     <div className=\"Container\">\n//       {isLoading ? (\n//         <div\n//           style={{\n//             color: \"white\",\n//           }}\n//         >\n//           객체 인식 중\n//         </div>\n//       ) : (\n//         <>\n//           {videoUrl ? (\n//             <button\n//               onClick={() => {\n//                 const a = document.createElement(\"a\");\n//                 a.href = videoUrl;\n//                 const videoName = `video_${new Date().getTime()}.mp4`;\n//                 a.download = videoName;\n//                 a.click();\n//               }}\n//             >\n//               다운로드\n//             </button>\n//           ) : (\n//             <Webcam\n//               height={400}\n//               width={400}\n//               audio={false}\n//               mirrored={true}\n//               ref={webcamRef}\n//               videoConstraints={videoConstraints}\n//             />\n//           )}\n//           {recording ? (\n//             <button onClick={handleStopRecording}>Stop Recording</button>\n//           ) : (\n//             <button onClick={handleStartRecording}>Start Recording</button>\n//           )}\n//         </>\n//       )}\n//     </div>\n//   );\n// }\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs\";\n\n// 웹캠 비디오 요소를 가져옵니다.\nconst videoElement = document.getElementById(\"video\");\n\n// 웹캠 비디오 스트림을 가져옵니다.\nnavigator.mediaDevices.getUserMedia({\n  video: true\n}).then(stream => {\n  // 웹캠 비디오 요소에 스트림을 설정합니다.\n  videoElement.srcObject = stream;\n  videoElement.onloadedmetadata = () => {\n    // 웹캠 비디오 로드 완료 후 객체 인식 모델을 로드하고 실행합니다.\n    loadModelAndDetect();\n  };\n});\nasync function loadModelAndDetect() {\n  // 사용자가 만든 TensorFlow.js 모델을 로드합니다.\n  const model = await tf.loadLayersModel(\"../detect/tfjs_model/model.json\");\n\n  // 비디오 요소에서 프레임을 캡처하고 객체 인식을 수행합니다.\n  function detectObjects() {\n    // 비디오 프레임 캡처\n    const image = tf.browser.fromPixels(videoElement);\n    const expandedImage = image.expandDims(0);\n\n    // 객체 인식 실행\n    const predictions = model.predict(expandedImage);\n\n    // 결과 처리\n    // 예측 결과를 활용하여 실시간으로 객체 인식 결과를 화면에 표시하는 로직을 구현합니다.\n\n    // 다음 프레임을 처리하기 위해 재귀적으로 호출\n    requestAnimationFrame(detectObjects);\n  }\n\n  // 객체 인식 실행\n  detectObjects();\n}","map":{"version":3,"names":["React","useState","useRef","useEffect","Webcam","axios","Analysising","tf","videoElement","document","getElementById","navigator","mediaDevices","getUserMedia","video","then","stream","srcObject","onloadedmetadata","loadModelAndDetect","model","loadLayersModel","detectObjects","image","browser","fromPixels","expandedImage","expandDims","predictions","predict","requestAnimationFrame"],"sources":["/Users/minjeongyeom/Projects/project-wildet/wildet/src/components/WebcamVideo.jsx"],"sourcesContent":["import React, { useState, useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport axios from \"axios\";\nimport Analysising from \"./Analysising\";\n\n// export default function WebcamVideo() {\n//   const webcamRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const [recording, setRecording] = useState(false);\n//   const [videoUrl, setVideoUrl] = useState(\"\");\n//   const [isLoading, setIsLoading] = useState(false);\n\n//   const handleStartRecording = () => {\n//     setRecording(true);\n//     mediaRecorderRef.current = new MediaRecorder(webcamRef.current.stream);\n//     mediaRecorderRef.current.addEventListener(\n//       \"dataavailable\",\n//       handleDataAvailable\n//     );\n//     mediaRecorderRef.current.start();\n//   };\n\n//   const handleDataAvailable = (event) => {\n//     if (event.data.size > 0) {\n//       const videoBlob = new Blob([event.data], { type: \"video/mp4\" });\n//       const formData = new FormData();\n//       formData.append(\"file\", videoBlob);\n//       setIsLoading(true);\n//       axios\n//         .post(\"http://localhost:5000/detect\", formData, {\n//           headers: {\n//             \"Content-Type\": \"multipart/form-data\",\n//           },\n//           withCredentials: true,\n//           responseType: \"blob\", // blob 유형으로 응답 받음\n//         })\n//         .then((response) => {\n//           console.log(\"성공\");\n\n//           const videoBlob = new Blob([response.data], {\n//             type: \"video/mp4\",\n//           });\n\n//           setIsLoading(false);\n\n//           const videoUrl1 = URL.createObjectURL(videoBlob); // URL 객체로 변환\n//           setVideoUrl(videoUrl1);\n\n//           // const a = document.createElement(\"a\");\n//           // a.href = videoUrl1;\n//           // const videoName = `video_${new Date().getTime()}.mp4`;\n//           // a.download = videoName;\n//           // a.click();\n//         });\n//     }\n//   };\n\n//   console.log(videoUrl);\n\n//   const handleStopRecording = () => {\n//     mediaRecorderRef.current.stop();\n//   };\n\n//   const videoConstraints = {\n//     width: 420,\n//     height: 420,\n//     facingMode: \"user\",\n//   };\n\n//   // const handleVideoLoaded = (event) => {\n//   //   event.target.play();\n//   // };\n\n//   return (\n//     <div className=\"Container\">\n//       {isLoading ? (\n//         <div\n//           style={{\n//             color: \"white\",\n//           }}\n//         >\n//           객체 인식 중\n//         </div>\n//       ) : (\n//         <>\n//           {videoUrl ? (\n//             <button\n//               onClick={() => {\n//                 const a = document.createElement(\"a\");\n//                 a.href = videoUrl;\n//                 const videoName = `video_${new Date().getTime()}.mp4`;\n//                 a.download = videoName;\n//                 a.click();\n//               }}\n//             >\n//               다운로드\n//             </button>\n//           ) : (\n//             <Webcam\n//               height={400}\n//               width={400}\n//               audio={false}\n//               mirrored={true}\n//               ref={webcamRef}\n//               videoConstraints={videoConstraints}\n//             />\n//           )}\n//           {recording ? (\n//             <button onClick={handleStopRecording}>Stop Recording</button>\n//           ) : (\n//             <button onClick={handleStartRecording}>Start Recording</button>\n//           )}\n//         </>\n//       )}\n//     </div>\n//   );\n// }\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs\";\n\n// 웹캠 비디오 요소를 가져옵니다.\nconst videoElement = document.getElementById(\"video\");\n\n// 웹캠 비디오 스트림을 가져옵니다.\nnavigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {\n  // 웹캠 비디오 요소에 스트림을 설정합니다.\n  videoElement.srcObject = stream;\n  videoElement.onloadedmetadata = () => {\n    // 웹캠 비디오 로드 완료 후 객체 인식 모델을 로드하고 실행합니다.\n    loadModelAndDetect();\n  };\n});\n\nasync function loadModelAndDetect() {\n  // 사용자가 만든 TensorFlow.js 모델을 로드합니다.\n  const model = await tf.loadLayersModel(\"../detect/tfjs_model/model.json\");\n\n  // 비디오 요소에서 프레임을 캡처하고 객체 인식을 수행합니다.\n  function detectObjects() {\n    // 비디오 프레임 캡처\n    const image = tf.browser.fromPixels(videoElement);\n    const expandedImage = image.expandDims(0);\n\n    // 객체 인식 실행\n    const predictions = model.predict(expandedImage);\n\n    // 결과 처리\n    // 예측 결과를 활용하여 실시간으로 객체 인식 결과를 화면에 표시하는 로직을 구현합니다.\n\n    // 다음 프레임을 처리하기 위해 재귀적으로 호출\n    requestAnimationFrame(detectObjects);\n  }\n\n  // 객체 인식 실행\n  detectObjects();\n}\n"],"mappings":"AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAC1D,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAOC,KAAK,MAAM,OAAO;AACzB,OAAOC,WAAW,MAAM,eAAe;;AAEvC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,kBAAkB;;AAEzB;AACA,MAAMC,YAAY,GAAGC,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC;;AAErD;AACAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC,CAACC,IAAI,CAAEC,MAAM,IAAK;EACpE;EACAR,YAAY,CAACS,SAAS,GAAGD,MAAM;EAC/BR,YAAY,CAACU,gBAAgB,GAAG,MAAM;IACpC;IACAC,kBAAkB,EAAE;EACtB,CAAC;AACH,CAAC,CAAC;AAEF,eAAeA,kBAAkBA,CAAA,EAAG;EAClC;EACA,MAAMC,KAAK,GAAG,MAAMb,EAAE,CAACc,eAAe,CAAC,iCAAiC,CAAC;;EAEzE;EACA,SAASC,aAAaA,CAAA,EAAG;IACvB;IACA,MAAMC,KAAK,GAAGhB,EAAE,CAACiB,OAAO,CAACC,UAAU,CAACjB,YAAY,CAAC;IACjD,MAAMkB,aAAa,GAAGH,KAAK,CAACI,UAAU,CAAC,CAAC,CAAC;;IAEzC;IACA,MAAMC,WAAW,GAAGR,KAAK,CAACS,OAAO,CAACH,aAAa,CAAC;;IAEhD;IACA;;IAEA;IACAI,qBAAqB,CAACR,aAAa,CAAC;EACtC;;EAEA;EACAA,aAAa,EAAE;AACjB"},"metadata":{},"sourceType":"module","externalDependencies":[]}